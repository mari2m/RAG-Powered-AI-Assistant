{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1401544,"sourceType":"datasetVersion","datasetId":819052}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-26T18:46:58.790755Z","iopub.execute_input":"2024-08-26T18:46:58.791127Z","iopub.status.idle":"2024-08-26T18:47:55.278755Z","shell.execute_reply.started":"2024-08-26T18:46:58.791092Z","shell.execute_reply":"2024-08-26T18:47:55.277498Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Function to load data from folders\ndef load_data_from_folders(main_folder_path):\n    data = []\n    for category_folder in os.listdir(main_folder_path):\n        category_label = category_folder  # Assuming folder name is the category label\n        category_path = os.path.join(main_folder_path, category_folder)\n        for file_name in os.listdir(category_path):\n            file_path = os.path.join(category_path, file_name)\n            with open(file_path, 'r', encoding='utf-8') as file:\n                content = file.read()\n                data.append({'text': content, 'category': category_label})\n    return pd.DataFrame(data)\n\n# Main folder containing subfolders for each category\nmain_folder_path = '/kaggle/input/sanad-dataset'\n\n# Load data from folders\ndf = load_data_from_folders(main_folder_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:47:55.281060Z","iopub.execute_input":"2024-08-26T18:47:55.281516Z","iopub.status.idle":"2024-08-26T18:52:11.485132Z","shell.execute_reply.started":"2024-08-26T18:47:55.281467Z","shell.execute_reply":"2024-08-26T18:52:11.484055Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:52:11.486434Z","iopub.execute_input":"2024-08-26T18:52:11.486787Z","iopub.status.idle":"2024-08-26T18:52:11.510496Z","shell.execute_reply.started":"2024-08-26T18:52:11.486751Z","shell.execute_reply":"2024-08-26T18:52:11.509294Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                    text category\n0      دبي - \"الخليج\":حصدت شعاع كابيتال جائزة \"أفضل ش...  Finance\n1      أبوظبي - علي أسعد: تراجعت أسواق المال في الدول...  Finance\n2      استأنفت أسواق الأسهم المحلية أمس تحركها باتجاه...  Finance\n3      دبي «الخليج»: أعلنت شركة تكافل الإمارات عن بدء...  Finance\n4      تحتفل شركة طاقة الخليج البحرية، التي تتخذ من د...  Finance\n...                                                  ...      ...\n45495  على هامش مشاركتها في أسبوع جيتكس للتقنية أعلنت...     Tech\n45496  أعلنت شركة إيه أم دي، عن طرح أحدث منصات الكمبي...     Tech\n45497  أبوظبي \"الخليج\":زار الفريق سيف عبدالله الشعفار...     Tech\n45498  تشارك وزارة الاقتصاد في الدورة ال 33 لأسبوع جي...     Tech\n45499  تم انتخاب لويس حكيم، نائب رئيس رويال فيليبس لل...     Tech\n\n[45500 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>دبي - \"الخليج\":حصدت شعاع كابيتال جائزة \"أفضل ش...</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>أبوظبي - علي أسعد: تراجعت أسواق المال في الدول...</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>استأنفت أسواق الأسهم المحلية أمس تحركها باتجاه...</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>دبي «الخليج»: أعلنت شركة تكافل الإمارات عن بدء...</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>تحتفل شركة طاقة الخليج البحرية، التي تتخذ من د...</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>45495</th>\n      <td>على هامش مشاركتها في أسبوع جيتكس للتقنية أعلنت...</td>\n      <td>Tech</td>\n    </tr>\n    <tr>\n      <th>45496</th>\n      <td>أعلنت شركة إيه أم دي، عن طرح أحدث منصات الكمبي...</td>\n      <td>Tech</td>\n    </tr>\n    <tr>\n      <th>45497</th>\n      <td>أبوظبي \"الخليج\":زار الفريق سيف عبدالله الشعفار...</td>\n      <td>Tech</td>\n    </tr>\n    <tr>\n      <th>45498</th>\n      <td>تشارك وزارة الاقتصاد في الدورة ال 33 لأسبوع جي...</td>\n      <td>Tech</td>\n    </tr>\n    <tr>\n      <th>45499</th>\n      <td>تم انتخاب لويس حكيم، نائب رئيس رويال فيليبس لل...</td>\n      <td>Tech</td>\n    </tr>\n  </tbody>\n</table>\n<p>45500 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:52:18.703068Z","iopub.execute_input":"2024-08-26T18:52:18.703976Z","iopub.status.idle":"2024-08-26T18:52:18.735344Z","shell.execute_reply.started":"2024-08-26T18:52:18.703935Z","shell.execute_reply":"2024-08-26T18:52:18.734287Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 45500 entries, 0 to 45499\nData columns (total 2 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   text      45500 non-null  object\n 1   category  45500 non-null  object\ndtypes: object(2)\nmemory usage: 711.1+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:52:19.152226Z","iopub.execute_input":"2024-08-26T18:52:19.153219Z","iopub.status.idle":"2024-08-26T18:52:19.352332Z","shell.execute_reply.started":"2024-08-26T18:52:19.153172Z","shell.execute_reply":"2024-08-26T18:52:19.351180Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                     text category\ncount                                               45500    45500\nunique                                              45485        7\ntop     إعداد: محمد صالح القرق دخل على رسول الله- صلى ...  Finance\nfreq                                                    3     6500","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>45500</td>\n      <td>45500</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>45485</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>إعداد: محمد صالح القرق دخل على رسول الله- صلى ...</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>3</td>\n      <td>6500</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:52:20.286935Z","iopub.execute_input":"2024-08-26T18:52:20.287319Z","iopub.status.idle":"2024-08-26T18:52:20.305377Z","shell.execute_reply.started":"2024-08-26T18:52:20.287283Z","shell.execute_reply":"2024-08-26T18:52:20.304257Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"text        0\ncategory    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"#lowercasing and removing special characters\ndf['text'] = df['text'].str.lower().str.replace(r'\\W', ' ', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:52:21.650059Z","iopub.execute_input":"2024-08-26T18:52:21.651053Z","iopub.status.idle":"2024-08-26T18:52:29.645125Z","shell.execute_reply.started":"2024-08-26T18:52:21.651006Z","shell.execute_reply":"2024-08-26T18:52:29.644052Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:52:29.646977Z","iopub.execute_input":"2024-08-26T18:52:29.647349Z","iopub.status.idle":"2024-08-26T18:52:29.661359Z","shell.execute_reply.started":"2024-08-26T18:52:29.647311Z","shell.execute_reply":"2024-08-26T18:52:29.660317Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                                    text category\n0      دبي    الخليج  حصدت شعاع كابيتال جائزة  أفضل ش...  Finance\n1      أبوظبي   علي أسعد  تراجعت أسواق المال في الدول...  Finance\n2      استأنفت أسواق الأسهم المحلية أمس تحركها باتجاه...  Finance\n3      دبي  الخليج   أعلنت شركة تكافل الإمارات عن بدء...  Finance\n4      تحتفل شركة طاقة الخليج البحرية  التي تتخذ من د...  Finance\n...                                                  ...      ...\n45495  على هامش مشاركتها في أسبوع جيتكس للتقنية أعلنت...     Tech\n45496  أعلنت شركة إيه أم دي  عن طرح أحدث منصات الكمبي...     Tech\n45497  أبوظبي  الخليج  زار الفريق سيف عبدالله الشعفار...     Tech\n45498  تشارك وزارة الاقتصاد في الدورة ال 33 لأسبوع جي...     Tech\n45499  تم انتخاب لويس حكيم  نائب رئيس رويال فيليبس لل...     Tech\n\n[45500 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>دبي    الخليج  حصدت شعاع كابيتال جائزة  أفضل ش...</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>أبوظبي   علي أسعد  تراجعت أسواق المال في الدول...</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>استأنفت أسواق الأسهم المحلية أمس تحركها باتجاه...</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>دبي  الخليج   أعلنت شركة تكافل الإمارات عن بدء...</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>تحتفل شركة طاقة الخليج البحرية  التي تتخذ من د...</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>45495</th>\n      <td>على هامش مشاركتها في أسبوع جيتكس للتقنية أعلنت...</td>\n      <td>Tech</td>\n    </tr>\n    <tr>\n      <th>45496</th>\n      <td>أعلنت شركة إيه أم دي  عن طرح أحدث منصات الكمبي...</td>\n      <td>Tech</td>\n    </tr>\n    <tr>\n      <th>45497</th>\n      <td>أبوظبي  الخليج  زار الفريق سيف عبدالله الشعفار...</td>\n      <td>Tech</td>\n    </tr>\n    <tr>\n      <th>45498</th>\n      <td>تشارك وزارة الاقتصاد في الدورة ال 33 لأسبوع جي...</td>\n      <td>Tech</td>\n    </tr>\n    <tr>\n      <th>45499</th>\n      <td>تم انتخاب لويس حكيم  نائب رئيس رويال فيليبس لل...</td>\n      <td>Tech</td>\n    </tr>\n  </tbody>\n</table>\n<p>45500 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pip install transformers faiss-cpu","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:52:29.662653Z","iopub.execute_input":"2024-08-26T18:52:29.663049Z","iopub.status.idle":"2024-08-26T18:52:45.899203Z","shell.execute_reply.started":"2024-08-26T18:52:29.663006Z","shell.execute_reply":"2024-08-26T18:52:45.897850Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nDownloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.8.0.post1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport faiss\nfrom transformers import DistilBertTokenizer, DistilBertModel\nimport torch\n","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:52:45.900921Z","iopub.execute_input":"2024-08-26T18:52:45.901273Z","iopub.status.idle":"2024-08-26T18:52:51.085858Z","shell.execute_reply.started":"2024-08-26T18:52:45.901237Z","shell.execute_reply":"2024-08-26T18:52:51.084900Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Initialize DistilBERT\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\nmodel = DistilBertModel.from_pretrained('distilbert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:52:51.089400Z","iopub.execute_input":"2024-08-26T18:52:51.090104Z","iopub.status.idle":"2024-08-26T18:52:57.365388Z","shell.execute_reply.started":"2024-08-26T18:52:51.090062Z","shell.execute_reply":"2024-08-26T18:52:57.364422Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"772f9ead22654b85afda7219a77ef7e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf3b8561e5224efcae6e2ac6ae2cec7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd931e47b6434612bc4371feed068d56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eb954cebefd49b59bb8c8274e3adbc2"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de4c2d137a2c4d54802a3febf940da18"}},"metadata":{}}]},{"cell_type":"code","source":"def encode_documents(texts):\n    embeddings = []\n    for text in texts:\n        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n        with torch.no_grad():\n            outputs = model(**inputs)\n            # Take the mean of token embeddings as document embeddings\n            embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n            embeddings.append(embedding)\n    return embeddings\n","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:52:57.366610Z","iopub.execute_input":"2024-08-26T18:52:57.366975Z","iopub.status.idle":"2024-08-26T18:52:57.373568Z","shell.execute_reply.started":"2024-08-26T18:52:57.366938Z","shell.execute_reply":"2024-08-26T18:52:57.372292Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Sample 1,000 rows\ndf = df.sample(n=1000, random_state=42) ","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:52:57.375126Z","iopub.execute_input":"2024-08-26T18:52:57.375498Z","iopub.status.idle":"2024-08-26T18:52:57.390301Z","shell.execute_reply.started":"2024-08-26T18:52:57.375453Z","shell.execute_reply":"2024-08-26T18:52:57.389112Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:52:57.391685Z","iopub.execute_input":"2024-08-26T18:52:57.392068Z","iopub.status.idle":"2024-08-26T18:52:57.400727Z","shell.execute_reply.started":"2024-08-26T18:52:57.392031Z","shell.execute_reply":"2024-08-26T18:52:57.399695Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(1000, 2)"},"metadata":{}}]},{"cell_type":"code","source":"# Encode documents\ndocument_embeddings = encode_documents(df['text'].tolist())","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:52:57.402321Z","iopub.execute_input":"2024-08-26T18:52:57.403034Z","iopub.status.idle":"2024-08-26T19:00:56.522262Z","shell.execute_reply.started":"2024-08-26T18:52:57.402986Z","shell.execute_reply":"2024-08-26T19:00:56.521281Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Create FAISS index\ndimension = document_embeddings[0].shape[0]\nindex = faiss.IndexFlatL2(dimension)\nindex.add(np.array(document_embeddings))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-26T19:00:56.523601Z","iopub.execute_input":"2024-08-26T19:00:56.524161Z","iopub.status.idle":"2024-08-26T19:00:56.531636Z","shell.execute_reply.started":"2024-08-26T19:00:56.524121Z","shell.execute_reply":"2024-08-26T19:00:56.530656Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Save the index\nfaiss.write_index(index, 'document_index.faiss')","metadata":{"execution":{"iopub.status.busy":"2024-08-26T19:00:56.532934Z","iopub.execute_input":"2024-08-26T19:00:56.533259Z","iopub.status.idle":"2024-08-26T19:00:56.543386Z","shell.execute_reply.started":"2024-08-26T19:00:56.533225Z","shell.execute_reply":"2024-08-26T19:00:56.542393Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\n# Load FAISS index\nindex = faiss.read_index('document_index.faiss')","metadata":{"execution":{"iopub.status.busy":"2024-08-26T19:00:56.544715Z","iopub.execute_input":"2024-08-26T19:00:56.545152Z","iopub.status.idle":"2024-08-26T19:01:11.379368Z","shell.execute_reply.started":"2024-08-26T19:00:56.545107Z","shell.execute_reply":"2024-08-26T19:01:11.378275Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\n# Initialize text generation pipeline\ngenerator = pipeline('text-generation', model='gpt2')\n\ndef generate_answer(query):\n    # Encode the query\n    query_embedding = encode_documents([query])[0]\n    \n    # Retrieve relevant documents\n    _, indices = index.search(np.array([query_embedding]), k=5)  # Retrieve top 5 documents\n    retrieved_docs = [df.iloc[idx]['text'] for idx in indices[0]]\n    \n    # Combine retrieved documents into a context for generation\n    context = ' '.join(retrieved_docs)\n    \n    # Ensure the context is within the acceptable length\n    if len(context) > 1024:\n        context = context[:1024]  # truncate to fit model's max length\n\n    # Generate response\n    generated = generator(f\"Context: {context}\\n\\nQuestion: {query}\", max_length=200, max_new_tokens=150)\n    \n    return generated[0]['generated_text']\n\n# Test the model\nprint(generate_answer(\"What is the main theme of the dataset?\"))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-26T19:01:11.380865Z","iopub.execute_input":"2024-08-26T19:01:11.381702Z","iopub.status.idle":"2024-08-26T19:01:29.408729Z","shell.execute_reply.started":"2024-08-26T19:01:11.381644Z","shell.execute_reply":"2024-08-26T19:01:29.407574Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"086f640a1eb24e009df2910f23b69b57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eac75ca664034c4287646cb79c570d5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"450f49c690d141909ff746a60186d064"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6374dd4ed5ea42eb905091479d042074"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8357f32b3ba48418e82c5d25be52abb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e503992610254f4d821c36c3b73946f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf9f1080f675461aa87ce41ed9aa6859"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nBoth `max_new_tokens` (=150) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"Context: ارتفع مؤشر الصقر الصادر عن المال كابيتال 43 45 نقطة توازي 2  ليغلق عند 2149 91 نقطة  وكانت أكثر الشركات ارتفاعا   الواحة بنسبة 8 8   الاتحاد العقارية 5 48   أملاك 4 69   دانة غاز 4 48    تصدر جهاز iomega ego portable hard drive 500gb لائحة أفضل خمسة أقراص صلبة خارجية قابلة للحمل والتنقل بحسب موقع بي سي ورلد 1iomega ego portable hard drive 500gb  السعة  500 غيغابايت    المنافذ المدعومة  firewire 400  firewire 800  usb 2  0  الملحقات  usb 2  0   power cable  firewire 400cable  firewire 800 cable   البرامج الملحقة  retrospect express  iomega quikprotect  الضمان  3 سنوات    السعر عند اعداد التقرير  150 دولار  2western digital mypassport essential se 1tb   السعة  1000غيغابايت    المنافذ المدعومة  usb 2  0  سرعة الدوران  5400 دورة في الدقيقة    الملحقات  mini usb cable  البرامج الملحقة  wd smartware   الضمان  سنة واحدة    السعر عند اعداد التقرير  25  178 دولار  3wiebetech toughtechxe mini 500gb   السعة  500 غيغابايت    المنافذ المدعومة  external sata 300  firewire 800  usb 2  0  سرعة الدوران  5400 دورة في الدقيقة  \n\nQuestion: What is the main theme of the dataset?بتلائة  شيغة امنانت ارتفاعا  كقل غارد اثباطلا  يوستما بحتدي وفةتود امنانت ارتفاعا  ارتفاعا  فلاه خلار ان وصلو بنتوه اصقاغ ربتليت اصو ان فقل �\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test the model\nprint(generate_answer(\"التهاب الكبد الوبائي\"))","metadata":{"execution":{"iopub.status.busy":"2024-08-26T19:01:29.411823Z","iopub.execute_input":"2024-08-26T19:01:29.412186Z","iopub.status.idle":"2024-08-26T19:01:35.743341Z","shell.execute_reply.started":"2024-08-26T19:01:29.412148Z","shell.execute_reply":"2024-08-26T19:01:35.742265Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nBoth `max_new_tokens` (=150) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"Context: صادقت الجمعية العمومية لشركة  دبي الوطني للتأمين وإعادة التأمين  المنعقدة أمس على توزيع أرباح نقدية للمساهمين بنسبة 20  من رأس المال عن عام 2013   أعلن سوق دبي المالي عن إيداع أسهم المنحة لشركة بيت التمويل الخليجي بنسبة 20  في حسابات المساهمين وذلك كما في تاريخ إغلاق سجل الشركة في 22 2 2009   أعلن مجلس إدارة شركة سوق دبي المالي أنه اجتمع يوم الاثنين بتاريخ 27 9 2010 واعتمد البنود المتعلقة بتوصيات لجنة الترشيحات والمكافآت  والهيكل التنظيمي للشركة   ينظم بيت الشعر ندوة حوارية بعنوان دغدغة قصيدة النثر  يشترك فيها د   بهجت الحديثي وعبداللطيف الزبيدي ويقدم الندوة ويديرها عبدالفتاح صبري  وذلك في الثامنة من مساء اليوم   ينعقد اجتماع شركة صروح العقارية يوم 27 يوليو تموز الجاري  وذلك لمناقشة الانجازات المالية للربع الثاني من عام  2011 ومراجعة أمور عامة وتشغيلية واستراتيجية  \n\nQuestion: التهاب الكبد الوبائي�اري - ها وا الينواء فيأوول السقاصه الناتد الاةن، الجمعية العمومية لصادقت الجمعية لشركة بيت التمويل الخ�اري\n\n5. يولقبت النصاده اجمع الؽوعة قنام نر عطيرة بحلام �\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# Path to the main dataset folder\ndataset_path = '/kaggle/input/sanad-dataset'  # Update this path to the location of your dataset\n\n# Categories (folder names)\ncategories = ['Culture', 'Finance', 'Medical', 'Politics', 'Religion', 'Sports', 'Tech']\n\n# Initialize a list to hold the data in chunks\ndata_chunks = []\n\n# Process each category folder\nfor category in categories:\n    category_path = os.path.join(dataset_path, category)\n    for file_name in os.listdir(category_path):\n        file_path = os.path.join(category_path, file_name)\n        # Ensure it's a text file\n        if file_name.endswith('.txt'):\n            with open(file_path, 'r', encoding='utf-8') as file:\n                content = file.read()\n                # Append the content and category to the data list\n                data_chunks.append({'text': content, 'category': category})\n        \n        # Save in chunks to avoid memory issues\n        if len(data_chunks) >= 1000:  # Adjust the chunk size as needed\n            chunk_df = pd.DataFrame(data_chunks)\n            chunk_df.to_csv('sanad_combined2.csv', mode='a', index=False, header=not os.path.exists('sanad_combined.csv'))\n            data_chunks = []  # Clear the list to free up memory\n\n# Save any remaining data\nif data_chunks:\n    chunk_df = pd.DataFrame(data_chunks)\n    chunk_df.to_csv('sanad_combined2.csv', mode='a', index=False, header=not os.path.exists('sanad_combined.csv'))\n\nprint(\"Data successfully combined and saved in chunks!\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:06:42.013860Z","iopub.execute_input":"2024-08-27T08:06:42.014749Z","iopub.status.idle":"2024-08-27T08:06:55.999935Z","shell.execute_reply.started":"2024-08-27T08:06:42.014705Z","shell.execute_reply":"2024-08-27T08:06:55.998742Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Ensure it's a text file\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     23\u001b[0m         content \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;66;03m# Append the content and category to the data list\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/codecs.py:309\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.__init__\u001b[0;34m(self, errors)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBufferedIncrementalDecoder\u001b[39;00m(IncrementalDecoder):\n\u001b[1;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    This subclass of IncrementalDecoder can be used as the baseclass for an\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m    incremental decoder if the decoder must be able to handle incomplete\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m    byte sequences.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    310\u001b[0m         IncrementalDecoder\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors)\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;66;03m# undecoded input that is kept between calls to decode()\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Load the dataset and skip the first row\ndata = pd.read_csv('sanad_combined2.csv', delimiter=',', skiprows=1, names=['text', 'category'])\n\n# Verify that the data is loaded correctly\nprint(data.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-26T20:51:57.458789Z","iopub.status.idle":"2024-08-26T20:51:57.459186Z","shell.execute_reply.started":"2024-08-26T20:51:57.458993Z","shell.execute_reply":"2024-08-26T20:51:57.459013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-08-26T20:51:57.460507Z","iopub.status.idle":"2024-08-26T20:51:57.460895Z","shell.execute_reply.started":"2024-08-26T20:51:57.460715Z","shell.execute_reply":"2024-08-26T20:51:57.460734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:46:41.073009Z","iopub.execute_input":"2024-08-27T09:46:41.073755Z","iopub.status.idle":"2024-08-27T09:46:46.699009Z","shell.execute_reply.started":"2024-08-27T09:46:41.073706Z","shell.execute_reply":"2024-08-27T09:46:46.698202Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\n# Function to load data from folders\ndef load_data_from_folders(main_folder_path):\n    data = []\n    for category_folder in os.listdir(main_folder_path):\n        category_label = category_folder  # Assuming folder name is the category label\n        category_path = os.path.join(main_folder_path, category_folder)\n        for file_name in os.listdir(category_path):\n            file_path = os.path.join(category_path, file_name)\n            with open(file_path, 'r', encoding='utf-8') as file:\n                content = file.read()\n                data.append({'text': content, 'category': category_label})\n    return pd.DataFrame(data)\n\n# Main folder containing subfolders for each category\nmain_folder_path = '/kaggle/input/sanad-dataset'\n\n# Load data from folders\ndata = load_data_from_folders(main_folder_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:46:46.700834Z","iopub.execute_input":"2024-08-27T09:46:46.701249Z","iopub.status.idle":"2024-08-27T09:51:32.126797Z","shell.execute_reply.started":"2024-08-27T09:46:46.701215Z","shell.execute_reply":"2024-08-27T09:51:32.125935Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:51:32.128195Z","iopub.execute_input":"2024-08-27T09:51:32.128834Z","iopub.status.idle":"2024-08-27T09:51:32.157235Z","shell.execute_reply.started":"2024-08-27T09:51:32.128783Z","shell.execute_reply":"2024-08-27T09:51:32.156377Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                    text category\n0      دبي - \"الخليج\":حصدت شعاع كابيتال جائزة \"أفضل ش...  Finance\n1      أبوظبي - علي أسعد: تراجعت أسواق المال في الدول...  Finance\n2      استأنفت أسواق الأسهم المحلية أمس تحركها باتجاه...  Finance\n3      دبي «الخليج»: أعلنت شركة تكافل الإمارات عن بدء...  Finance\n4      تحتفل شركة طاقة الخليج البحرية، التي تتخذ من د...  Finance\n...                                                  ...      ...\n45495  على هامش مشاركتها في أسبوع جيتكس للتقنية أعلنت...     Tech\n45496  أعلنت شركة إيه أم دي، عن طرح أحدث منصات الكمبي...     Tech\n45497  أبوظبي \"الخليج\":زار الفريق سيف عبدالله الشعفار...     Tech\n45498  تشارك وزارة الاقتصاد في الدورة ال 33 لأسبوع جي...     Tech\n45499  تم انتخاب لويس حكيم، نائب رئيس رويال فيليبس لل...     Tech\n\n[45500 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>دبي - \"الخليج\":حصدت شعاع كابيتال جائزة \"أفضل ش...</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>أبوظبي - علي أسعد: تراجعت أسواق المال في الدول...</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>استأنفت أسواق الأسهم المحلية أمس تحركها باتجاه...</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>دبي «الخليج»: أعلنت شركة تكافل الإمارات عن بدء...</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>تحتفل شركة طاقة الخليج البحرية، التي تتخذ من د...</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>45495</th>\n      <td>على هامش مشاركتها في أسبوع جيتكس للتقنية أعلنت...</td>\n      <td>Tech</td>\n    </tr>\n    <tr>\n      <th>45496</th>\n      <td>أعلنت شركة إيه أم دي، عن طرح أحدث منصات الكمبي...</td>\n      <td>Tech</td>\n    </tr>\n    <tr>\n      <th>45497</th>\n      <td>أبوظبي \"الخليج\":زار الفريق سيف عبدالله الشعفار...</td>\n      <td>Tech</td>\n    </tr>\n    <tr>\n      <th>45498</th>\n      <td>تشارك وزارة الاقتصاد في الدورة ال 33 لأسبوع جي...</td>\n      <td>Tech</td>\n    </tr>\n    <tr>\n      <th>45499</th>\n      <td>تم انتخاب لويس حكيم، نائب رئيس رويال فيليبس لل...</td>\n      <td>Tech</td>\n    </tr>\n  </tbody>\n</table>\n<p>45500 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pip install faiss-gpu\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:51:32.159070Z","iopub.execute_input":"2024-08-27T09:51:32.159358Z","iopub.status.idle":"2024-08-27T09:51:50.900702Z","shell.execute_reply.started":"2024-08-27T09:51:32.159328Z","shell.execute_reply":"2024-08-27T09:51:50.899431Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-gpu\nSuccessfully installed faiss-gpu-1.7.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade ipywidgets","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:51:50.902226Z","iopub.execute_input":"2024-08-27T09:51:50.902553Z","iopub.status.idle":"2024-08-27T09:52:05.869328Z","shell.execute_reply.started":"2024-08-27T09:51:50.902521Z","shell.execute_reply":"2024-08-27T09:52:05.868148Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\nCollecting ipywidgets\n  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\nRequirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.21.0)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\nCollecting widgetsnbextension~=4.0.12 (from ipywidgets)\n  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\nCollecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\n  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\nDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hDownloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n  Attempting uninstall: widgetsnbextension\n    Found existing installation: widgetsnbextension 3.6.8\n    Uninstalling widgetsnbextension-3.6.8:\n      Successfully uninstalled widgetsnbextension-3.6.8\n  Attempting uninstall: jupyterlab-widgets\n    Found existing installation: jupyterlab_widgets 3.0.11\n    Uninstalling jupyterlab_widgets-3.0.11:\n      Successfully uninstalled jupyterlab_widgets-3.0.11\n  Attempting uninstall: ipywidgets\n    Found existing installation: ipywidgets 7.7.1\n    Uninstalling ipywidgets-7.7.1:\n      Successfully uninstalled ipywidgets-7.7.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\nbigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\nbigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\ndataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.8.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport faiss\nfrom transformers import DistilBertTokenizer, DistilBertModel, pipeline\nimport torch\nimport numpy as np\nimport gc\n\n# Initialize DistilBERT\nprint(\"Initializing DistilBERT model and tokenizer...\")\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\nmodel = DistilBertModel.from_pretrained('distilbert-base-uncased').to(device)\nprint(\"Model and tokenizer initialized.\")\n\n\ndef encode_batch(texts):\n    print(f\"Encoding batch of size: {len(texts)}\")\n    inputs = tokenizer(texts, return_tensors='pt', truncation=True, padding=True, max_length=512).to(device)\n    with torch.no_grad():\n        outputs = model(**inputs)\n        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move back to CPU before converting to numpy\n    print(\"Batch encoding complete.\")\n    return embeddings\n\ndef process_and_index_chunk(start_index, end_index, index):\n    print(f\"Processing chunk from index {start_index} to {end_index}...\")\n    batch_texts = data['text'][start_index:end_index].tolist()\n    \n    # Split batch into smaller sub-batches to avoid OOM\n    sub_batch_size = 100  # You can adjust this\n    for i in range(0, len(batch_texts), sub_batch_size):\n        sub_batch_texts = batch_texts[i:i + sub_batch_size]\n        batch_embeddings = encode_batch(sub_batch_texts)\n        print(f\"Adding {len(batch_embeddings)} embeddings to the FAISS index...\")\n        index.add(batch_embeddings)\n        \n        # Free up memory\n        del batch_embeddings\n        gc.collect()  # Call garbage collector\n        print(f\"Sub-batch {i // sub_batch_size + 1} processed and indexed.\")\n\ndef generate_answer(query, index, data):\n    print(f\"Generating answer for query: {query}\")\n    \n    # Encode the query\n    query_embedding = encode_batch([query])[0]\n    \n    # Retrieve relevant documents (limit to top 3 for faster generation)\n    print(\"Searching for relevant documents...\")\n    _, indices = index.search(np.array([query_embedding]), k=3)\n    retrieved_docs = [data.iloc[idx]['text'] for idx in indices[0]]\n    print(f\"Retrieved documents: {retrieved_docs}\")\n    \n    # Truncate the context if it's too long\n    context = ' '.join(retrieved_docs)\n    if len(context) > 1024:\n        context = context[:1024]\n    \n    # Generate response\n    print(\"Generating response using GPT-2...\")\n    generator = pipeline('text-generation', model='gpt2', device=device)  # Use GPU if available\n    generated = generator(f\"Context: {context}\\n\\nQuestion: {query}\", max_new_tokens=150)\n    \n    print(\"Response generated.\")\n    return generated[0]['generated_text']\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:52:05.871239Z","iopub.execute_input":"2024-08-27T09:52:05.871944Z","iopub.status.idle":"2024-08-27T09:52:31.891200Z","shell.execute_reply.started":"2024-08-27T09:52:05.871882Z","shell.execute_reply":"2024-08-27T09:52:31.890237Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Initializing DistilBERT model and tokenizer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd1661d4ca6c464eb69e479bcab23cff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"827a01fcb3664dc7a45906469efe97f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42732ee04b81481c931bd6330319be14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f981a0cac5f4919a8deb107a90742b6"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eda9f5e9158c4cbb84275de40ef67ee4"}},"metadata":{}},{"name":"stdout","text":"Model and tokenizer initialized.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize the FAISS index\ndimension = 768  # DistilBERT's output dimension\nindex = faiss.IndexFlatL2(dimension)\nprint(\"FAISS index initialized.\")\n\n# Process data in chunks\nchunk_size = 1000  # Adjust based on your available memory\nfor start in range(0, len(data), chunk_size):\n    end = min(start + chunk_size, len(data))\n    process_and_index_chunk(start, end, index)\n    print(f\"Processed chunk from {start} to {end}.\")\n\n# Save the index\nprint(\"Saving the FAISS index...\")\nfaiss.write_index(index, 'document_index_optimized.faiss')\nprint(\"FAISS index saved.\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T09:52:31.892553Z","iopub.execute_input":"2024-08-27T09:52:31.893614Z","iopub.status.idle":"2024-08-27T10:22:19.579304Z","shell.execute_reply.started":"2024-08-27T09:52:31.893564Z","shell.execute_reply":"2024-08-27T10:22:19.578059Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"FAISS index initialized.\nProcessing chunk from index 0 to 1000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 0 to 1000.\nProcessing chunk from index 1000 to 2000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 1000 to 2000.\nProcessing chunk from index 2000 to 3000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 2000 to 3000.\nProcessing chunk from index 3000 to 4000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 3000 to 4000.\nProcessing chunk from index 4000 to 5000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 4000 to 5000.\nProcessing chunk from index 5000 to 6000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 5000 to 6000.\nProcessing chunk from index 6000 to 7000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 6000 to 7000.\nProcessing chunk from index 7000 to 8000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 7000 to 8000.\nProcessing chunk from index 8000 to 9000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 8000 to 9000.\nProcessing chunk from index 9000 to 10000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 9000 to 10000.\nProcessing chunk from index 10000 to 11000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 10000 to 11000.\nProcessing chunk from index 11000 to 12000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 11000 to 12000.\nProcessing chunk from index 12000 to 13000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 12000 to 13000.\nProcessing chunk from index 13000 to 14000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 13000 to 14000.\nProcessing chunk from index 14000 to 15000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 14000 to 15000.\nProcessing chunk from index 15000 to 16000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 15000 to 16000.\nProcessing chunk from index 16000 to 17000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 16000 to 17000.\nProcessing chunk from index 17000 to 18000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 17000 to 18000.\nProcessing chunk from index 18000 to 19000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 18000 to 19000.\nProcessing chunk from index 19000 to 20000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 19000 to 20000.\nProcessing chunk from index 20000 to 21000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 20000 to 21000.\nProcessing chunk from index 21000 to 22000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 21000 to 22000.\nProcessing chunk from index 22000 to 23000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 22000 to 23000.\nProcessing chunk from index 23000 to 24000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 23000 to 24000.\nProcessing chunk from index 24000 to 25000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 24000 to 25000.\nProcessing chunk from index 25000 to 26000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 25000 to 26000.\nProcessing chunk from index 26000 to 27000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 26000 to 27000.\nProcessing chunk from index 27000 to 28000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 27000 to 28000.\nProcessing chunk from index 28000 to 29000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 28000 to 29000.\nProcessing chunk from index 29000 to 30000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 29000 to 30000.\nProcessing chunk from index 30000 to 31000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 30000 to 31000.\nProcessing chunk from index 31000 to 32000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 31000 to 32000.\nProcessing chunk from index 32000 to 33000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 32000 to 33000.\nProcessing chunk from index 33000 to 34000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 33000 to 34000.\nProcessing chunk from index 34000 to 35000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 34000 to 35000.\nProcessing chunk from index 35000 to 36000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 35000 to 36000.\nProcessing chunk from index 36000 to 37000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 36000 to 37000.\nProcessing chunk from index 37000 to 38000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 37000 to 38000.\nProcessing chunk from index 38000 to 39000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 38000 to 39000.\nProcessing chunk from index 39000 to 40000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 39000 to 40000.\nProcessing chunk from index 40000 to 41000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 40000 to 41000.\nProcessing chunk from index 41000 to 42000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 41000 to 42000.\nProcessing chunk from index 42000 to 43000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 42000 to 43000.\nProcessing chunk from index 43000 to 44000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 43000 to 44000.\nProcessing chunk from index 44000 to 45000...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 6 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 7 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 8 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 9 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 10 processed and indexed.\nProcessed chunk from 44000 to 45000.\nProcessing chunk from index 45000 to 45500...\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 1 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 2 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 3 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 4 processed and indexed.\nEncoding batch of size: 100\nBatch encoding complete.\nAdding 100 embeddings to the FAISS index...\nSub-batch 5 processed and indexed.\nProcessed chunk from 45000 to 45500.\nSaving the FAISS index...\nFAISS index saved.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test the optimized model\nquery = \"ماذا حدث في اغتيال البرلماني عبد اللطيف مرداس\"\nprint(\"Testing the model...\")\nanswer = generate_answer(query, index, data)\nprint(f\"Answer: {answer}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-27T10:22:19.580759Z","iopub.execute_input":"2024-08-27T10:22:19.581413Z","iopub.status.idle":"2024-08-27T10:22:28.453925Z","shell.execute_reply.started":"2024-08-27T10:22:19.581368Z","shell.execute_reply":"2024-08-27T10:22:28.452861Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Testing the model...\nGenerating answer for query: ماذا حدث في اغتيال البرلماني عبد اللطيف مرداس\nEncoding batch of size: 1\nBatch encoding complete.\nSearching for relevant documents...\nRetrieved documents: ['تنظم ندوة الثقافة والعلوم في مقرها في دبي عند العاشرة والنصف من صباح اليوم مؤتمراً صحفياً للإعلان عن الفائزين في جائزة العويس للإبداع .', 'ينظم النادي الثقافي العربي أمسية للشاعر حسن عبدالسلام أبودية عند الثامنة من مساء يوم غد في مقر النادي في الشارقة .', 'استعرض ابن علي السيارة النموذجية «رين سبيد إيتوس» ذات الابتكارات الفائقة والتقنيات الجديدة التي تغير عالم التنقل.']\nGenerating response using GPT-2...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9eca7fa577f148a2831b93cd433f0d89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef79557a39444ed39bf75ca2d1757f51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0483c3b8ced4506913eed233c2ae770"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e8f763c012c450082f9f2bf85b27320"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76983f70d8144d19bd3b3571e9817d64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"107b9e5ff3e44be79ea974fc21445c61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa76330b35ae46068e086203cbeaf38a"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Response generated.\nAnswer: Context: تنظم ندوة الثقافة والعلوم في مقرها في دبي عند العاشرة والنصف من صباح اليوم مؤتمراً صحفياً للإعلان عن الفائزين في جائزة العويس للإبداع . ينظم النادي الثقافي العربي أمسية للشاعر حسن عبدالسلام أبودية عند الثامنة من مساء يوم غد في مقر النادي في الشارقة . استعرض ابن علي السيارة النموذجية «رين سبيد إيتوس» ذات الابتكارات الفائقة والتقنيات الجديدة التي تغير عالم التنقل.\n\nQuestion: ماذا حدث في اغتيال البرلماني عبد اللطيف مرداس وأتفاثي بن أوضكاب الأوتسانا ين وتهيف الأخما بن أبودية أبودية أبيته والعربي انما جسداخ العقوم بحدث اللم.\n\n[5] In other words, صالم المسفلوافن was given to أبودية, and not to اءكتف.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline\n\n# Load FAISS index\nindex = faiss.read_index('document_index_optimized.faiss')\n\ndef generate_answer(query):\n    # Encode the query\n    query_embedding = encode_batch([query])[0]\n    \n    # Retrieve relevant documents (limit to top 3 for faster generation)\n    _, indices = index.search(np.array([query_embedding]), k=3)\n    retrieved_docs = [data.iloc[idx]['text'] for idx in indices[0]]\n    \n    # Combine the retrieved documents into a context\n    context = ' '.join(retrieved_docs)\n    \n    # Truncate the context if it's too long (important for Arabic)\n    if len(context) > 1024:\n        context = context[:1024]\n    \n    # Use an Arabic-specific model for generation\n    generator = pipeline('text-generation', model='aubmindlab/aragpt2-base', device=0)\n    prompt = f\"السياق: {context}\\n\\nالسؤال: {query}\\n\\nالجواب:\"\n    generated = generator(prompt, max_new_tokens=150, pad_token_id=50256)\n    \n    return generated[0]['generated_text']\n\n# Test the model with an Arabic question\nprint(generate_answer(\"ما هو مشروع الحملة الوطنية للتخلص من الالتهاب الكبدي الوبائي «سي»؟\"))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T10:22:28.455152Z","iopub.execute_input":"2024-08-27T10:22:28.455485Z","iopub.status.idle":"2024-08-27T10:22:35.914641Z","shell.execute_reply.started":"2024-08-27T10:22:28.455451Z","shell.execute_reply":"2024-08-27T10:22:35.913691Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Encoding batch of size: 1\nBatch encoding complete.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f81beac9c004b07ac7736029c699b23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/553M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db31372f04c54eff9e6bec439f91c084"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ac917d3729244d3b3fc0ea4972b713e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.50M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6403cc402dc442deb0924b715475eeca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/4.52M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cefe5ab9426644d5a8e8320e358851d4"}},"metadata":{}},{"name":"stdout","text":"السياق: كان سهم بنك الخليج الأول أمس نجم التداولات في الأسواق المحلية إذ بلغت 4 .940 مليون درهم نتيجة صفقة تحويل 56 مليون سهم، إلا أن السهم تراجع بنسبة 3 .0% إلى 7 .15 درهم .. .وكابيتال انتليجنس ترفع تصنيفهرفعت وكالة كابيتال انتليجنس تصنيف القوة المالية لبنك الخليج الأول من درجة A إلى درجة A+، ومنحته نظرة مستقبلية مستقرة، في ضوء التحسن العام للأسس المالية للبنك، وخصوصاً فيما يتعلق بجودة الأصول والربحية والسيولة المالية . دبي - \"الخليج\":أجل اجتماع الجمعية العمومية لشركة \"شعاع كابيتال\" الذي كان مقرراً أمس الأول إلى الاثنين 7 إبريل/ نيسان المقبل . أبوظبي - \"الخليج\":أقرت الجمعية العمومية لشركة دار التمويل اقتراح مجلس الإدارة بتوزيع أرباح نقدية بنسبة 20% وأسهم منحة بنسبة 5 .2% عن العام الماضي .\n\nالسؤال: ما هو مشروع الحملة الوطنية للتخلص من الالتهاب الكبدي الوبائي «سي»؟\n\nالجواب: هل أنت مصاب بالأنيميا ؟ وما هي أعراض مرضك ؟ وهل لديك نقص في فيتامين ب 12 ؟ كل ما عليك القيام به هو استشارة الطبيبالأمراض التي تصيب الكبد والكلى والجهاز الهضمي والقلب والسرطان والسكري وأمراض الجهاز التنفسيإذا كنت مصابا بأحد الأمراض المزمنة مثل أمراض القلب أو السكري أو ضغط الدم أو الضغط أو السمنة أو غيرها ، فأنت بحاجة إلى تناول المزيد من الفيتامينات والمعادن والأحماض الدهنية أوميجا - 3 وكذلك حمض الفوليك والحديد والزنك والبوتاسيوم والمنجنيز وفيتامين ( ج ) وذلك لأنها تساعد على حماية الجسم من الإصابة بمرض السرطان والأمراض القلبية الوعائية والتي قد تؤدي إلى الوفاة إذا لم يتم تناولها بانتظام.هناك بعض الأطعمة التي تحتوي على نسبة عالية من الأحماض الدهنية الأوميغا - 3 مثل سمك السلمون والماكريل والتونة وبذور الكتان واللوز\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Test the model with an Arabic question\nprint(generate_answer(\"ما هي مواعيد معهد الشارقة للفنون؟\"))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T10:22:35.919314Z","iopub.execute_input":"2024-08-27T10:22:35.919622Z","iopub.status.idle":"2024-08-27T10:22:38.634232Z","shell.execute_reply.started":"2024-08-27T10:22:35.919589Z","shell.execute_reply":"2024-08-27T10:22:38.633290Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Encoding batch of size: 1\nBatch encoding complete.\nالسياق: تنظم ندوة الثقافة والعلوم في مقرها في دبي عند العاشرة والنصف من صباح اليوم مؤتمراً صحفياً للإعلان عن الفائزين في جائزة العويس للإبداع . أقرت الجمعية العمومية للمؤسسة الوطنية للسياحة والفنادق توزيع 60% أرباحاً نقدية على مساهميها يوم أمس الأول . تقرر عقد اجتماع مجلس إدارة دار التأمين الخميس المقبل الساعة الثانية والنصف بعد الظهر لمناقشة الموازنة التقديرية لسنة 2013 .\n\nالسؤال: ما هي مواعيد معهد الشارقة للفنون؟\n\nالجواب: عقدت اللجنة التنفيذية لمعهد الشارقة للفنون اجتماعها الدوري الخامس عشر برئاسة د. عبد الله بن محمد العويس رئيس مجلس إدارة المعهد ، حيث ناقش الاجتماع عددا من الموضوعات المدرجة على جدول أعماله واتخذ بشأنها القرارات والتوصيات المناسبة.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_name = \"aubmindlab/aragpt2-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\n\ndef calculate_perplexity(text):\n    inputs = tokenizer(text, return_tensors='pt')\n    with torch.no_grad():\n        outputs = model(**inputs, labels=inputs['input_ids'])\n        loss = outputs.loss\n    return torch.exp(loss).item()\n\ntext = \"مجلوبة من موقع [رابط]! ؟ ( 1 2 3 4 5... الصفحة الأخيرة )عنوان الموضوع المشاركة الأخيرة تاريخ بداية الموضوع عدد الردود عدد المشاهدات كاتب الموضوع تقييم الموضوعآخر يوم آخر يومين آخر أسبوع آخر 10 أيام آخر أسبوعين آخر شهر آخر 45 يوم آخر شهرين آخر 75 يوم آخر 100 يوم السنة الماضية البدايةلوحة تحكم العضو الرسائل الخاصة الاشتراكات المتواجدون الآن البحث في المنتدى الصفحة الرئيسية للمنتدى منتدى الأسهم منتدى الأخبار الاقتصادية منتدى ألاكاديمية للدروس والتحليل الفني تسجيلات والبث المباشر للقوائم اثناء التداول منتدى الأسهم السعودية أساتذة الأكاديمية.. في القنوات الإعلامية. منتدى برامج الأسهم وشروحاتها برنامج الميتاستوك برنامج ويلث لاب ( Wealth - Lab ) برنامج الإيمي بروكر برنامج MotiveWave برنامج تكرتشارت برنامج\"\nperplexity = calculate_perplexity(text)\nprint(f\"Perplexity: {perplexity}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T10:22:38.635818Z","iopub.execute_input":"2024-08-27T10:22:38.636221Z","iopub.status.idle":"2024-08-27T10:22:40.151066Z","shell.execute_reply.started":"2024-08-27T10:22:38.636176Z","shell.execute_reply":"2024-08-27T10:22:40.149963Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Perplexity: 5.820170879364014\n","output_type":"stream"}]},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu\n\ndef calculate_bleu_score(references, hypotheses):\n    references = [[ref.split()] for ref in references]\n    hypotheses = [hyp.split() for hyp in hypotheses]\n    score = corpus_bleu(references, hypotheses)\n    return score\n\n# Example\nreferences = [\"ما هو مشروع الحملة الوطنية للتخلص من الالتهاب الكبدي الوبائي «سي»؟\"]\nhypotheses = [\"مجلوبة من موقع [رابط]! ؟ ( 1 2 3 4 5... الصفحة الأخيرة )عنوان الموضوع المشاركة الأخيرة تاريخ بداية الموضوع عدد الردود عدد المشاهدات كاتب الموضوع تقييم الموضوعآخر يوم آخر يومين آخر أسبوع آخر 10 أيام آخر أسبوعين آخر شهر آخر 45 يوم آخر شهرين آخر 75 يوم آخر 100 يوم السنة الماضية البدايةلوحة تحكم العضو الرسائل الخاصة الاشتراكات المتواجدون الآن البحث في المنتدى الصفحة الرئيسية للمنتدى منتدى الأسهم منتدى الأخبار الاقتصادية منتدى ألاكاديمية للدروس والتحليل الفني تسجيلات والبث المباشر للقوائم اثناء التداول منتدى الأسهم السعودية أساتذة الأكاديمية.. في القنوات الإعلامية. منتدى برامج الأسهم وشروحاتها برنامج الميتاستوك برنامج ويلث لاب ( Wealth - Lab ) برنامج الإيمي بروكر برنامج MotiveWave برنامج تكرتشارت برنامج\"]\nbleu_score = calculate_bleu_score(references, hypotheses)\nprint(f\"BLEU Score: {bleu_score}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T10:22:40.152867Z","iopub.execute_input":"2024-08-27T10:22:40.153575Z","iopub.status.idle":"2024-08-27T10:22:41.110214Z","shell.execute_reply.started":"2024-08-27T10:22:40.153516Z","shell.execute_reply":"2024-08-27T10:22:41.109269Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"BLEU Score: 0.3067117324758864\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 2-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}